{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Попытка представить процесс визуально\n",
    "## Пробуем на вкус matplotlib\n",
    "### 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'usd_rate.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18588/2230344135.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHuberRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdataframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"usd_rate.xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mrate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcurs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mlength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\project\\offlinexaa-working_analysis\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\project\\offlinexaa-working_analysis\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mc:\\project\\offlinexaa-working_analysis\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1189\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1191\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1192\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1193\u001b[0m                 )\n",
      "\u001b[1;32mc:\\project\\offlinexaa-working_analysis\\venv\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1068\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1070\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m   1071\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m     ) as handle:\n",
      "\u001b[1;32mc:\\project\\offlinexaa-working_analysis\\venv\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 711\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'usd_rate.xlsx'"
     ]
    }
   ],
   "source": [
    "# Начальные объявления\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Модели для пункта 4)\n",
    "from sklearn.linear_model import ARDRegression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.linear_model import HuberRegressor\n",
    "\n",
    "dataframe = pandas.read_excel(\"usd_rate_28.xlsx\")\n",
    "rate = dataframe.curs\n",
    "length = len(rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_all(past = 28):  # Вынесем в отдельную функцию все для заполнения выборок\n",
    "    past_days = []        # из чего составляем данные\n",
    "    current_day = []\n",
    "    past_columns = []\n",
    "    global rate, length\n",
    "    for day in range(past, length):\n",
    "        slc = list(rate[(day-past):day])\n",
    "        past_days.append(slc)   \n",
    "        current_day.append(rate[day]) \n",
    "    for i in range(past):\n",
    "        past_columns.append(f\"past_{i}\")\n",
    "    global X,y\n",
    "    X = pandas.DataFrame(data=past_days, columns=past_columns)\n",
    "    y = pandas.Series(current_day, name='target')\n",
    "    global X_train\n",
    "    X_train = X[:-10]   # Закроем глаза на использование глобальных переменных\n",
    "    global y_train\n",
    "    y_train = y[:-10] \n",
    "    global X_test\n",
    "    X_test = X[-10:]    # зато тестить удобно\n",
    "    global y_test\n",
    "    y_test = y[-10:]    # Да и попытка \"в лоб\" сделать это через возврат кортежа потерпела неудачу\n",
    "    # return X[:-size], y[:-size], X[-size:], y[-size:]\n",
    "    # return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуем вынести в отдельную функцию расчет и отрисовку моделей для отображения на 1 графике\n",
    "def make_and_paint(*models):\n",
    "    best_model = \"\"\n",
    "    best_mae = 2        # костыль, теоретически погрешность может быть дофига, но на практике видел лишь 1.*\n",
    "    best_msqe = 0       # эта штука тут только для разнообразия метрик погрешностей\n",
    "    for model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        prediction = model.predict(X_test)\n",
    "        plt.plot(prediction, label=f\"Prediction of {model}\")\n",
    "        mae = mean_absolute_error(prediction, y_test)\n",
    "        msqe = mean_squared_error(prediction, y_test)\n",
    "        print(f\"MAE of {model} = {mae}\")\n",
    "        print(f\"MSQE of {model} = {msqe}\")\n",
    "        if mae < best_mae:\n",
    "            best_mae = mae\n",
    "            best_msqe = msqe\n",
    "            best_model = model\n",
    "    # Как-то выделим наш реальный курс, спасибо гугль\n",
    "    plt.plot(list(y_test), label=f\"Real\", linewidth=5, linestyle=':', dash_capstyle='round')\n",
    "    # Перенесем легенду вбок, чтобы на тестовом графике она не заслоняла половину графика\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    # Жирненько выделим нашу лучшую модель\n",
    "    print('\\033[1m' + f\"Best model was {best_model} with mae = {best_mae} msqe = {best_msqe}\" + '\\033[0m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train, X_test, y_test = filldays(std_past)   \n",
    "fill_all()   # Заполним массивы для \"стандартного\" отрезка в 28 дней"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Экспериментируем с моделью MLPRegressor\n",
    "# Дополнение - результаты вычислений - какой-то рандом, меняющийся в два с лишним раза просто при перезапуске\n",
    "# кода. так что здесь просто перебором выберем что-нибудь покрасивее с разумным количеством параметров\n",
    "# взяв линейную регрессию как \"эталон\" качества.\n",
    "# Возможно, зная теорию, можно будет подбирать их с умом, а пока... как то так\n",
    "\n",
    "lr_model = LinearRegression()    # Линейная модель для сравнения\n",
    "mlp_model1 = MLPRegressor()\n",
    "mlp_model2 = MLPRegressor(max_iter=1000, hidden_layer_sizes=(200, 200, 200))\n",
    "\n",
    "# activation logistic и tanh выдали бОльшую погрешность\n",
    "# а identity чаще выдавал лучшие результаты чем стандартный relu\n",
    "\n",
    "mlp_model3 = MLPRegressor(max_iter=1000, hidden_layer_sizes=(300, 300, 300), activation = 'identity')\n",
    "\n",
    "# sgf solver выдает предупреждения и ошибки, ну и черт с ним. Выбранному солверу явно нужно мнооого операций\n",
    "# а вот activation незаметно чтобы влиял\n",
    "\n",
    "mlp_model4 = MLPRegressor(max_iter=5000, hidden_layer_sizes=(300, 300, 300), activation = 'identity', solver = 'lbfgs')\n",
    "mlp_model5 = MLPRegressor(max_iter=5000, hidden_layer_sizes=(300, 300, 300), solver = 'lbfgs')\n",
    "mlp_model6 = MLPRegressor(max_iter=5000, hidden_layer_sizes=(100, 200, 300), activation = 'identity', solver = 'lbfgs')\n",
    "mlp_model7 = MLPRegressor(max_iter=5000, hidden_layer_sizes=(100, 200, 300), solver = 'lbfgs')\n",
    "mlp_model8 = MLPRegressor(max_iter=5000, hidden_layer_sizes=(300, 200, 100), activation = 'identity', solver = 'lbfgs')\n",
    "mlp_model9 = MLPRegressor(max_iter=5000, hidden_layer_sizes=(300, 200, 100), solver = 'lbfgs')\n",
    "\n",
    "# 6 и 7 модели часто выдают результат лучше чем линейная (0.37575 пока рекорд) так что остановимся на этом.\n",
    "# эксперименты с learning rate лишь ухудшали результат\n",
    "\n",
    "# страшный тестовый график\n",
    "# ------------------------\n",
    "# make_and_paint(lr_model, mlp_model1, mlp_model2, mlp_model3, mlp_model4, mlp_model5, mlp_model6, mlp_model7, mlp_model8, mlp_model9)\n",
    "# ------------------------\n",
    "# выведем красивый с линейной моделью и двумя нашими финалистками\n",
    "# Однако на нем часто сливается линейная модель с одной из наших.\n",
    "# Думаю есть технические способы разделить их более наглядно, но времени их искать нет\n",
    "make_and_paint(lr_model, mlp_model6, mlp_model7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для очистки совести, выберем еще 3 модели регрессии и сравним с линейной\n",
    "mor_model = ARDRegression()               # и так идеальна, выдает лучше чем обычная линейная \\0/\n",
    "ada_model = AdaBoostRegressor(n_estimators = 150)           # при стандарте - 0.58, так частенько 0.47-0.55\n",
    "                                                            # но вообще незаметно чтобы ее параметры часто влияли\n",
    "hub_model = HuberRegressor(max_iter = 2000, epsilon = 1.05) # 0.45 и предупреждение при стандарте \n",
    "                                                            # а вот при большем числе итераций и меньшем эпсилоне - чемпион\n",
    "make_and_paint(lr_model, mor_model, ada_model, hub_model)   #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Переходим на длительные предсказания (на прогнозы не похоже)\n",
    "### 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предсказания на 7 дней вперед. \n",
    "# Немного переделаем нашу функцию\n",
    "def fill_all_7(past = 28):  # Вынесем в отдельную функцию все для заполнения выборок\n",
    "    past_days = []               # из чего составляем данные\n",
    "    current_days = []\n",
    "    past_columns = []\n",
    "    future_columns = []\n",
    "    global rate, length\n",
    "    for day in range(past, length-6):\n",
    "        slc = list(rate[(day-past):day])\n",
    "        past_days.append(slc)\n",
    "        slc_future = list(rate[day:day+7])   # Кажется что должно быть +6, не забывать про особенность массивов pandas\n",
    "        current_days.append(slc_future) \n",
    "    for i in range(past):\n",
    "        past_columns.append(f\"past_{i}\")\n",
    "    for i in range(7):\n",
    "        future_columns.append(f\"future_{i}\")\n",
    "    global X,y   # больше костылей для теста\n",
    "    X = pandas.DataFrame(data=past_days, columns=past_columns)\n",
    "    y = pandas.DataFrame(data=current_days, columns=future_columns)\n",
    "    #y = pandas.Series(current_days, name='target') # Непонятная ошибка. По документации должно работать\n",
    "    global X_train       # То же самое, но в виде кучи отдельных строк\n",
    "    X_train = X[:-10]   \n",
    "    global y_train\n",
    "    y_train = y[:-10]   \n",
    "    global X_test\n",
    "    X_test = X[-10:]   \n",
    "    global y_test\n",
    "    y_test = y[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Разобраться и добавить работающий коннектор к БД"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполним массивы по новому\n",
    "fill_all_7()\n",
    "y_test\n",
    "   # ну вроде выводится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Все ниженаписанное (да и, возможно, вышенаписанное) по моему является абсолютно неверным из-за \n",
    "# неправильного понимания задания. Ну да ладно, что-то получилось, что-то даже нарисовалось. \n",
    "# Но не уверен что смогу придумать, что именно нарисовалось, и уж точно \n",
    "# не поставлю денег на правильность этих предсказаний :D\n",
    "\n",
    "# TODO: завернуть в функцию, ато расплодилось опять\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "na = np.array(y_test)\n",
    "prediction = lr_model.predict(X_test)\n",
    "mae = mean_absolute_error(prediction, y_test)\n",
    "msqe = mean_squared_error(prediction, y_test)\n",
    "print('\\033[1m' + f\"MAE равно {mae}; MSQE равно {msqe}, что бы это не значило\" + '\\033[0m')\n",
    "x = list(range(0,10))\n",
    "\n",
    "fig, axs = plt.subplots(7)\n",
    "for i in range(7):\n",
    "    axs[i].plot(x, prediction[:,i])\n",
    "    axs[i].plot(x, na[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Повторяем тот-же фокус с MLP четвертой модели\n",
    "mlp_model4.fit(X_train, y_train)\n",
    "na = np.array(y_test)\n",
    "prediction = mlp_model4.predict(X_test)\n",
    "mae = mean_absolute_error(prediction, y_test)\n",
    "msqe = mean_squared_error(prediction, y_test)\n",
    "print('\\033[1m' + f\"MAE равно {mae}; MSQE равно {msqe}, что бы это не значило\" + '\\033[0m')\n",
    "x = list(range(0,10))\n",
    "\n",
    "#print(prediction)\n",
    "fig, axs = plt.subplots(7)\n",
    "for i in range(7):\n",
    "    axs[i].plot(x, prediction[:,i])\n",
    "    axs[i].plot(x, na[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP пятой модели\n",
    "mlp_model5.fit(X_train, y_train)\n",
    "na = np.array(y_test)\n",
    "prediction = mlp_model5.predict(X_test)\n",
    "mae = mean_absolute_error(prediction, y_test)\n",
    "msqe = mean_squared_error(prediction, y_test)\n",
    "print('\\033[1m' + f\"MAE равно {mae}; MSQE равно {msqe}, что бы это не значило\" + '\\033[0m')\n",
    "x = list(range(0,10))\n",
    "\n",
    "#print(prediction)\n",
    "fig, axs = plt.subplots(7)\n",
    "for i in range(7):\n",
    "    axs[i].plot(x, prediction[:,i])\n",
    "    axs[i].plot(x, na[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP шестой модели\n",
    "mlp_model6.fit(X_train, y_train)\n",
    "na = np.array(y_test)\n",
    "prediction = mlp_model6.predict(X_test)\n",
    "mae = mean_absolute_error(prediction, y_test)\n",
    "msqe = mean_squared_error(prediction, y_test)\n",
    "print('\\033[1m' + f\"MAE равно {mae}; MSQE равно {msqe}, что бы это не значило\" + '\\033[0m')\n",
    "x = list(range(0,10))\n",
    "\n",
    "#print(prediction)\n",
    "fig, axs = plt.subplots(7)\n",
    "for i in range(7):\n",
    "    axs[i].plot(x, prediction[:,i])\n",
    "    axs[i].plot(x, na[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP седьмой модели\n",
    "mlp_model7.fit(X_train, y_train)\n",
    "na = np.array(y_test)\n",
    "prediction = mlp_model7.predict(X_test)\n",
    "mae = mean_absolute_error(prediction, y_test)\n",
    "msqe = mean_squared_error(prediction, y_test)\n",
    "print('\\033[1m' + f\"MAE равно {mae}; MSQE равно {msqe}, что бы это не значило\" + '\\033[0m')\n",
    "x = list(range(0,10))\n",
    "\n",
    "#print(prediction)\n",
    "fig, axs = plt.subplots(7)\n",
    "for i in range(7):\n",
    "    axs[i].plot(x, prediction[:,i])\n",
    "    axs[i].plot(x, na[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP восьмой модели\n",
    "mlp_model8.fit(X_train, y_train)\n",
    "na = np.array(y_test)\n",
    "prediction = mlp_model8.predict(X_test)\n",
    "mae = mean_absolute_error(prediction, y_test)\n",
    "msqe = mean_squared_error(prediction, y_test)\n",
    "print('\\033[1m' + f\"MAE равно {mae}; MSQE равно {msqe}, что бы это не значило\" + '\\033[0m')\n",
    "x = list(range(0,10))\n",
    "\n",
    "#print(prediction)\n",
    "fig, axs = plt.subplots(7)\n",
    "for i in range(7):\n",
    "    axs[i].plot(x, prediction[:,i])\n",
    "    axs[i].plot(x, na[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP девятой модели\n",
    "mlp_model9.fit(X_train, y_train)\n",
    "na = np.array(y_test)\n",
    "prediction = mlp_model9.predict(X_test)\n",
    "mae = mean_absolute_error(prediction, y_test)\n",
    "msqe = mean_squared_error(prediction, y_test)\n",
    "print('\\033[1m' + f\"MAE равно {mae}; MSQE равно {msqe}, что бы это не значило\" + '\\033[0m')\n",
    "x = list(range(0,10))\n",
    "\n",
    "#print(prediction)\n",
    "fig, axs = plt.subplots(7)\n",
    "for i in range(7):\n",
    "    axs[i].plot(x, prediction[:,i])\n",
    "    axs[i].plot(x, na[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лучше всего работают 5 и 9 модели MLP, но средняя ошибка около рубля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Возьмем отрезки по 7 дней, а не по 28, и снова посмотрим на погрешность\n",
    "fill_all(7)\n",
    "# И заново обработаем наши используемые модели\n",
    "make_and_paint(lr_model, mlp_model6, mlp_model7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_and_paint(lr_model, mor_model, ada_model, hub_model)\n",
    "# В общем можно сделать вывод что уменьшив количество дней для обучения погрешность растет при частых колебаниях\n",
    "# знака производной и снижается при сохранении знака производной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Сериализовать модель-победителя во внешний файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
